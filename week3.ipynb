{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "week3.ipynb",
      "collapsed_sections": [
        "E5E94vAHbONF",
        "uwQ_gIt4c8tS"
      ],
      "authorship_tag": "ABX9TyOOQF5ZolsB1jN2eaJ3LQbU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryuhyunwoo1/classDeepLearning/blob/main/week3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**real world examples of data tensors**\n",
        "\n",
        "Vector data - 2D tensor of shape (samples, features)\n",
        "\n",
        "Timeseries data or sequence data - 3D tensor of shape (samples, timestamps, features)\n",
        "\n",
        "Images - 4D tensor of shape (samples, height, width, channels)\n",
        "\n",
        "Video - 5D tensor of shape (shamples, frames, height, width, channels)"
      ],
      "metadata": {
        "id": "DwDYS1Ubah1O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**The gears of neural networks**\n",
        "\n",
        "Tensor operations applied to tensors of numeric data.\n",
        "\n",
        "\n",
        "Three tensor operations:\n",
        "\n",
        "**dot product** between input tensor and a tensor W\n",
        "\n",
        "**addition** between the resulting 2D tensor and vector b\n",
        "\n",
        "**relu operation** relu(x) is max(x,0)"
      ],
      "metadata": {
        "id": "E5E94vAHbONF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Naive implementation of an element-wise relu operation\n",
        "def naive_relu(x):\n",
        "  assert len(x.shape) == 2, 'x.ndim() must 2'\n",
        "\n",
        "  x = x.copy()\n",
        "  for i in range(x.shape[0]):\n",
        "    for j in range(x.shape[1]):\n",
        "      x[i,j] = max(x[i,j], 0)\n",
        "\n",
        "  return x"
      ],
      "metadata": {
        "id": "ie8kbv5YcHnu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Naive implementation of addition\n",
        "def naive_add(x, y):\n",
        "  assert len(x.shape) == 2\n",
        "  assert x.shape == y.shape\n",
        "\n",
        "  x = x.copy()\n",
        "  for i in range(x.shape[0]):\n",
        "    for j in range(x.shape[1]):\n",
        "      x[i,j] += y[i,j]\n",
        "\n",
        "  return x"
      ],
      "metadata": {
        "id": "lPlNtTsGckkH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Broadcasting**\n",
        "\n",
        "Broadcasting consists of two steps\n",
        "\n",
        "1. Axes (called broadcast axes) are added to the smaller tensor to match the ndim of the larger tensor.\n",
        "\n",
        "2. The smaller tensor is repeated alongside these new axes to match the full shape of the larger tensor."
      ],
      "metadata": {
        "id": "uwQ_gIt4c8tS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x = np.array([[1,1,1,1,1], [1,1,1,1,1]]) ## dimension is 2\n",
        "y = np.array([1,2,3,4,5]) ## dimension is 1\n",
        "\n",
        "def naive_add_matrix_and_vector(x, y):\n",
        "  assert len(x.shape) == 2\n",
        "  assert len(y.shape) == 1\n",
        "  assert x.shape[1] == y.shape[0]\n",
        "\n",
        "  x = x.copy()\n",
        "  for i in range(x.shape[0]):\n",
        "    for j in range(x.shape[1]):\n",
        "      x[i, j] += y[j]\n",
        "  return x"
      ],
      "metadata": {
        "id": "NqyrBQyjdTxZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x = np.random.random((64, 3, 32, 10))\n",
        "y = np.random.random((32, 10))\n",
        "z = np.maximum(x, y) ## The output z has shape (64, 3, 32, 10) like x."
      ],
      "metadata": {
        "id": "bFdhXejReUmA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Tensor dot**\n"
      ],
      "metadata": {
        "id": "pkzVqMQMe4hd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Dot product in math\n",
        "import numpy as np\n",
        "x = np.array([[1,1,1,1,1], [1,1,1,1,1]])\n",
        "y = np.array([1,2,3,4,5])\n",
        "z = np.dot(x, y)\n",
        "\n",
        "def naive_vector_dat(x, y):\n",
        "  assert len(x.shape) == 1\n",
        "  assert len(y.shape) == 1\n",
        "  assert x.shape[0] == y.shape[0]\n",
        "  z = 0.\n",
        "  for i in range(x.shape[0]):\n",
        "    z += x[i] * y[i]\n",
        "  return z"
      ],
      "metadata": {
        "id": "uZCEvQ1yfA0l"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_matrix_vector_dot(x,y):\n",
        "  assert len(x.shape) == 2   ## x is a Numpy matrix.\n",
        "  assert len(y.shape) == 1    ## y is a Numpy vector.\n",
        "  assert x.shape[1] == y.shape[0]   ## the first dimension of x must be the same as the 0th dimension of y\n",
        "  z = np.zeros(x.shape[0])    ## this operation returns a vector of 0s with the same shape as y\n",
        "\n",
        "  for i in range(x.shape[0]):\n",
        "    for j in range(x.shape[1]):\n",
        "      z [i] += x[i , j] * y[j]\n",
        "\n",
        "  return z"
      ],
      "metadata": {
        "id": "bOSimx4Rfn4f"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Dot product for 2D tensors\n",
        "def naive_matrix_dot(x, y):\n",
        "  assert len(x.shape) == 2\n",
        "  assert len(y.shape) == 2\n",
        "  assert x.shape[1] == y.shape[0]\n",
        "  z = np.zeros( (x.shape[0], y.shape[1]))\n",
        "\n",
        "  for i in range(x.shape[0]):\n",
        "    for j in range(y.shape[1]):\n",
        "      row_x = x[i, :]\n",
        "      column_y = y[:, j]\n",
        "      z[i, j] = naive_vector_dot(row_x, column_y)\n",
        "\n",
        "  return z"
      ],
      "metadata": {
        "id": "zVK9--U_iaC8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Tensor reshaping**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eBIKQUVsi8VP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## train_images = train_images.reshape((60000, 28 * 28))\n",
        "\n",
        "x = np.array([[0., 1.], [2., 3.] , [4., 5.]])\n",
        "x = x.reshape((6,1))\n",
        "x = x.reshape((2,3))\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IG3CYbPcjHQR",
        "outputId": "c1a80f99-a58d-4edc-84b2-cc2b48875b50"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 2.],\n",
              "       [3., 4., 5.]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}